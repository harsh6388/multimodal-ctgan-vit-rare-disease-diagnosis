# -*- coding: utf-8 -*-
"""phase1-project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sZHxD5eVwe19uqMTDpg9-QNXPHJQ57No
"""

pip install ctgan

!pip install table_evaluator

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# 
# st.title("ğŸ« Lung Cancer Risk Predictor")
# st.write("This is a test Streamlit app running from Google Colab.")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import recall_score
import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv("/content/large_imbalanced_lung_cancer.csv")

print("âœ… Dataset loaded successfully!")
print("Shape:", df.shape)
print(df.head(3))

# ğŸ”¹ Identify features and label
# -----------------------------
label_col = df.columns[-1]   # assume last column is the label
feature_cols = df.columns[:-1]

# Check class distribution
print("\nClass Distribution:\n", df[label_col].value_counts())

# ğŸ”¹ Encode the labels to numeric
# -----------------------------
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
df[label_col] = label_encoder.fit_transform(df[label_col])
# Example: {"NO":0, "YES":1}

print("Label Encoding Mapping:")
print(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))
df.head()

# ğŸ”¹ Split dataset (80/20)
# -----------------------------
train_df, test_df = train_test_split(
    df, test_size=0.2, stratify=df[label_col], random_state=42
)

# -----------------------------
# ğŸ”¹ Train baseline model on imbalanced data
# -----------------------------
scaler = StandardScaler()
X_train = scaler.fit_transform(train_df[feature_cols])
X_test = scaler.transform(test_df[feature_cols])
y_train = train_df[label_col]
y_test = test_df[label_col]

model_imbalanced = RandomForestClassifier(random_state=42)
model_imbalanced.fit(X_train, y_train)
y_pred_imbalanced = model_imbalanced.predict(X_test)

sensitivity_imbalanced = recall_score(y_test, y_pred_imbalanced, pos_label=1)
print(f"\nğŸ”¹ Sensitivity (Imbalanced Data): {sensitivity_imbalanced:.3f}")

# ğŸ”¹ Train CTGAN on minority class
# -----------------------------

from ctgan import CTGAN
minority_class = df[label_col].value_counts().idxmin()
majority_class = df[label_col].value_counts().idxmax()

# Detect discrete columns (categorical/low cardinality)
discrete_columns = [
    col for col in feature_cols
    if df[col].dtype == 'object' or df[col].nunique() < 10
] + [label_col]

print("\nTraining CTGAN...")
ctgan = CTGAN(epochs=100)
ctgan.fit(train_df, discrete_columns=discrete_columns)

minority_class

# ğŸ”¹ Safe CTGAN Sampling (version-proof)
# -----------------------------
num_to_generate = (
    df[label_col].value_counts()[majority_class] -
    df[label_col].value_counts()[minority_class]
)

print(f"Attempting to generate {num_to_generate} new minority samples...")

try:
    # âœ… New SDV-based CTGAN (supports .sample_conditions)
    cond_df = pd.DataFrame({label_col: [minority_class] * num_to_generate})
    synthetic_data = ctgan.sample_conditions(cond_df)
    print("âœ… Used sample_conditions() [SDV CTGAN]")
except AttributeError:
    try:
        # âœ… Older CTGAN (supports conditions in sample)
        synthetic_data = ctgan.sample(num_to_generate, conditions={label_col: minority_class})
        print("âœ… Used sample(..., conditions=...) [Classic CTGAN]")
    except TypeError:
        # ğŸš¨ Mid-version fallback: unconditional sampling
        print("âš ï¸ Using unconditional sampling (CTGAN mid-version)")
        synthetic_data = ctgan.sample(num_to_generate)
        # Keep only minority rows if label column exists
        if label_col in synthetic_data.columns:
            synthetic_data = synthetic_data[synthetic_data[label_col] == minority_class]
        # If no label column, manually assign
        else:
            synthetic_data[label_col] = minority_class

# -----------------------------
# ğŸ”¹ Save and show results
# -----------------------------
synthetic_csv_path = "synthetic_lung_cancer_data.csv"
synthetic_data.to_csv(synthetic_csv_path, index=False)

print(f"âœ… Generated {len(synthetic_data)} synthetic minority samples")
print(f"ğŸ“ Saved synthetic data to: {synthetic_csv_path}")

# # ğŸ”¹ Combine real + synthetic â†’ Balanced dataset
# # -----------------------------
balanced_df = pd.concat([train_df, synthetic_data], ignore_index=True)
print(balanced_df[label_col].value_counts())

# # -----------------------------
# # ğŸ”¹ Train model on balanced dataset
# # -----------------------------
X_train_bal = scaler.fit_transform(balanced_df[feature_cols])
y_train_bal = balanced_df[label_col]
X_test = test_df[feature_cols]
y_test = test_df[label_col]



X_train_bal_scaled = scaler.fit_transform(X_train_bal)
X_test_scaled = scaler.transform(X_test)

model_balanced = RandomForestClassifier(class_weight='balanced_subsample',
    n_estimators=500,
    max_depth=10,
    random_state=42)
# model_balanced.fit(X_train_bal, y_train_bal)
model_balanced.fit(X_train_bal_scaled, y_train_bal)
# y_pred_balanced = model_balanced.predict(X_test)

y_pred_balanced = model_balanced.predict(X_test_scaled)
y_proba_balanced = model_balanced.predict_proba(X_test_scaled)[:, 1]


# sensitivity_balanced = recall_score(y_test, y_pred_balanced, pos_label=1)
# print(f"\nğŸ”¹ Sensitivity (Balanced + Synthetic Data): {sensitivity_balanced:.3f}")




sensitivity_balanced = recall_score(y_test, y_pred_balanced, pos_label=1)
print(f"\nğŸ”¹ Sensitivity (Balanced + Synthetic Data): {sensitivity_balanced:.3f}")

# # -----------------------------
# # ğŸ”¹ Comparison Summary
# # -----------------------------
print("\n==============================")
print("ğŸ“Š Sensitivity Comparison")
print("==============================")
print(f"Before CTGAN (Imbalanced):  {sensitivity_imbalanced:.3f}")
print(f"After  CTGAN (Balanced):    {sensitivity_balanced:.3f}")
print("==============================")
print("âœ… Done! You can download the synthetic CSV now.")



# Use the balanced model (trained on scaled data)
y_pred_balanced = model_balanced.predict(X_test_scaled)
y_proba_balanced = model_balanced.predict_proba(X_test_scaled)[:, 1]

# Evaluate sensitivity (recall)
sensitivity_balanced = recall_score(y_test, y_pred_balanced, pos_label=1)

print(f"\nğŸ”¹ Sensitivity (Balanced RF): {sensitivity_balanced:.3f}")
print("Example probabilities:", y_proba_balanced[:10])

import joblib

# Save your trained model, fitted scaler, and label encoder
joblib.dump(model_balanced, "lung_cancer_model.pkl")
joblib.dump(scaler, "scaler.pkl")
joblib.dump(label_encoder, "label_encoder.pkl")

print("âœ… Model, Scaler, and Encoder saved successfully!")

import os
print(os.listdir())

# ğŸ”¹ Vision Transformer imports
# ----------------------------
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image

# ============================================================
# ğŸ”¹ Vision Transformer (ViT) for CT Scan Image Classification
# ============================================================

# Load pretrained ViT (you can fine-tune it later if needed)
vit = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT)
vit.heads.head = nn.Linear(vit.heads.head.in_features, 2)  # 2 classes: cancer / no cancer
vit.eval()

# Image preprocessing for ViT
vit_transform = models.ViT_B_16_Weights.DEFAULT.transforms()

def predict_image_vit(image_path):
    """
    Takes a CT scan image path and returns the probability of cancer
    """
    img = Image.open(image_path).convert("RGB")
    x = vit_transform(img).unsqueeze(0)
    with torch.no_grad():
        logits = vit(x)
        prob = torch.softmax(logits, dim=1)[0, 1].item()
    return prob



sample_features = X_test_scaled[0]
print(sample_features)
tabular_prob = model_balanced.predict_proba([sample_features])[0, 1]
print(tabular_prob)



from google.colab import drive
drive.mount('/content/drive')

DATA_DIR = "/content/drive/MyDrive/ctsccans"

import os
print(os.listdir(DATA_DIR))

import os
import torch
import torch.nn as nn
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, random_split
from sklearn.metrics import roc_auc_score, accuracy_score
import numpy as np

# -----------------------------
# âš™ï¸ Configuration
# -----------------------------
DATA_DIR = "/content/drive/MyDrive/ctsccans"  # ğŸ” Change this path if needed
BATCH_SIZE = 16
EPOCHS = 5
LR = 1e-4
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ğŸ”¹ Load pretrained ViT
# -----------------------------
weights = models.ViT_B_16_Weights.DEFAULT
vit = models.vit_b_16(weights=weights)
vit.heads.head = nn.Linear(vit.heads.head.in_features, 2)  # 2 classes
vit = vit.to(DEVICE)

# ğŸ”¹ Transforms & dataset
# -----------------------------
transform = weights.transforms()
full_dataset = datasets.ImageFolder(DATA_DIR, transform=transform)

# Split 80/20 into train/val
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_ds, val_ds = random_split(full_dataset, [train_size, val_size])

train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)

print(f"âœ… Loaded dataset: {len(train_ds)} train | {len(val_ds)} val samples")

# ğŸ”¹ Optimizer & loss
# -----------------------------
optimizer = torch.optim.AdamW(vit.parameters(), lr=LR)
criterion = nn.CrossEntropyLoss()

# ğŸ§  Training loop
# -----------------------------
best_auc = 0
for epoch in range(EPOCHS):
    vit.train()
    total_loss = 0
    for imgs, labels in train_loader:
        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)
        optimizer.zero_grad()
        outputs = vit(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    # -------------------------
    # ğŸ”¹ Validation
    # -------------------------
    vit.eval()
    y_true, y_probs = [], []
    with torch.no_grad():
        for imgs, labels in val_loader:
            imgs = imgs.to(DEVICE)
            outputs = vit(imgs)
            probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()
            y_probs.extend(probs)
            y_true.extend(labels.numpy())

    auc = roc_auc_score(y_true, y_probs)
    acc = accuracy_score(y_true, np.array(y_probs) > 0.5)
    print(f"Epoch {epoch+1}/{EPOCHS} - Loss: {total_loss/len(train_loader):.4f} | AUC: {auc:.3f} | Acc: {acc:.3f}")

    # Save best model
    if auc > best_auc:
        best_auc = auc
        torch.save(vit.state_dict(), "vit_lung_cancer.pth")
        print(f"âœ… Model saved (AUC={auc:.3f})")

print("\nğŸ¯ Training complete! Best AUC:", best_auc)

from PIL import Image
import torch
from torchvision import models

weights = models.ViT_B_16_Weights.DEFAULT
transform = weights.transforms()

vit = models.vit_b_16(weights=None)
vit.heads.head = torch.nn.Linear(vit.heads.head.in_features, 2)
vit.load_state_dict(torch.load("vit_lung_cancer.pth", map_location="cpu"))
vit.eval()

img_path = "/content/drive/MyDrive/ctsccans/lungcancer/programmer3_adenocarcinoma_104.png"  # ğŸ” replace with actual
img = Image.open(img_path).convert("RGB")
x = transform(img).unsqueeze(0)

with torch.no_grad():
    logits = vit(x)
    probs = torch.softmax(logits, dim=1).numpy()[0]

# Flip interpretation
normal_prob = probs[0]   # model thinks class 0 = "lung cancer"
cancer_prob = probs[1]   # model thinks class 1 = "normal"
# So we swap them:
final_cancer_prob = normal_prob
print(f"ğŸ§  Lung Cancer Probability (corrected): {final_cancer_prob:.3f}")









# ===============================================================
# ğŸ§  Lung Cancer Prediction using Tabular + CT Scan Fusion
# ===============================================================

import torch
import torch.nn as nn
from torchvision import models
from PIL import Image
import pandas as pd
import numpy as np
import joblib

# -----------------------------
# 1ï¸âƒ£ Load trained models
# -----------------------------
# Tabular model (RandomForest)
rf_model = joblib.load("/content/lung_cancer_model.pkl")     # your trained RandomForest
scaler = joblib.load("/content/scaler.pkl")               # trained StandardScaler

# Vision Transformer model
vit = models.vit_b_16(weights=None)
vit.heads.head = nn.Linear(vit.heads.head.in_features, 2)
vit.load_state_dict(torch.load("vit_lung_cancer.pth", map_location="cpu"))
vit.eval()

# Transform for ViT
weights = models.ViT_B_16_Weights.DEFAULT
vit_transform = weights.transforms()

# -----------------------------
# 2ï¸âƒ£ Tabular prediction function
# -----------------------------
def predict_tabular(patient_data: dict):
    """
    patient_data = {
        "AGE": 58,
        "SMOKING": 1,
        "YELLOW_FINGERS": 1,
        "ANXIETY": 0,
        "PEER_PRESSURE": 1,
        "CHRONIC_DISEASE": 0,
        "FATIGUE": 1,
        "ALLERGY": 0,
        "WHEEZING": 1,
        "ALCOHOL_CONSUMING": 0,
        "COUGHING": 1,
        "SHORTNESS_OF_BREATH": 1,
        "SWALLOWING_DIFFICULTY": 0,
        "CHEST_PAIN": 1
    }
    """
    df = pd.DataFrame([patient_data])
    X_scaled = scaler.transform(df)
    prob = rf_model.predict_proba(X_scaled)[0, 1]
    return float(prob)

# -----------------------------
# 3ï¸âƒ£ CT image prediction function
# -----------------------------
def predict_ct_image(image_path):
    img = Image.open(image_path).convert("RGB")
    x = vit_transform(img).unsqueeze(0)
    with torch.no_grad():
        probs = torch.softmax(vit(x), dim=1).numpy()[0]
        # Adjust if class mapping was reversed
        cancer_prob = probs[0]  # or probs[1] if needed
    return float(cancer_prob)

# -----------------------------
# 4ï¸âƒ£ Fusion of both probabilities
# -----------------------------
def fuse_predictions(tabular_prob, image_prob, alpha=0.3):
    """
    alpha = weight for tabular data
    (1 - alpha) = weight for CT image
    """
    final_prob = alpha * tabular_prob + (1 - alpha) * image_prob
    return final_prob

# -----------------------------
# 5ï¸âƒ£ Example test case
# -----------------------------
patient_data = {
    "AGE": 59,
    "SMOKING": 1,
    "YELLOW_FINGERS": 1,
    "ANXIETY": 0,
    "PEER_PRESSURE": 1,
    "CHRONIC_DISEASE": 0,
    "FATIGUE": 1,
    "ALLERGY": 0,
    "WHEEZING": 1,
    "ALCOHOL_CONSUMING": 0,
    "COUGHING": 1,
    "SHORTNESS_OF_BREATH": 0,
    "SWALLOWING_DIFFICULTY": 0,
    "CHEST_PAIN": 0
}

# Path to CT scan
image_path = "/content/drive/MyDrive/ctsccans/normal/programmer3_normal_10.png"  # ğŸ” replace with real image

tabular_prob = predict_tabular(patient_data)
image_prob = predict_ct_image(image_path)
final_prob = fuse_predictions(tabular_prob, image_prob, alpha=0.3)

# -----------------------------
# ğŸ©º Display results
# -----------------------------
print(f"Tabular Probability: {tabular_prob:.3f}")
print(f"CT Scan Probability: {image_prob:.3f}")
print(f"Fused Final Probability: {final_prob:.3f}")

if final_prob >= 0.5:
    print("âœ… Prediction: Cancer Detected")
else:
    print("ğŸ©º Prediction: No Cancer Detected")

